{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e0730ea-1316-4f07-8457-825283980e95",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Econ 1680: MLTA and Econ\n",
    "\n",
    "#### Name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18339078-2eec-466a-8fa8-2843f0346d0f",
   "metadata": {},
   "source": [
    "This assignment will cover applications of econometrics and machine learning we covered in class. For this assignment, you should write/type your answers into this notebook. You must also submit your python code. \n",
    "\n",
    "You may discuss the problem set with your class mates, but every student must do their own work. It is always important to cite our references that help us in our work. Please cite the students you work with here: ___ , ____, _____\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5d5c61-dff6-4e56-8811-10646aef170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c06c87",
   "metadata": {},
   "source": [
    "# I.     CODING EFFICIENCY AND COMMENTING\n",
    "Points will be given according to the efficiency and cleanliness of your code. It should produce output that answers the questions from the homework only and everything should be commented. Furthermore, your writeup and code should be submitted both to Canvas through Gradescope. These points are meant to encourage and reward good coding habits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebd5071",
   "metadata": {},
   "source": [
    "# II.     SIMULATED DATA AND MODEL MISSPECIFICATION\n",
    "#### 1.     Set the random seed to be equal to 1680."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69857c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above\n",
    "random.seed(1680)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a5d77",
   "metadata": {},
   "source": [
    "1a.     Generate a random integer between (0,10). Hint: use random.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3e902b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# Write the code you need (if any) to answer the questions above\n",
    "print(random.randint(0,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e474fc",
   "metadata": {},
   "source": [
    "1b.     What is that random integer? \\\n",
    "Answer: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a6cead",
   "metadata": {},
   "source": [
    "1c.     Why is it important to set a random seed when coding random variables?\\\n",
    "Answer: it allows for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ec85ee",
   "metadata": {},
   "source": [
    "#### 2. Comment to explain each line of code below and run the following code to generate data:\n",
    "*You will need to copy and paste the code below into a code block*:\n",
    "``` python\n",
    "rng=np.random.RandomState(1680) \n",
    "N = 100\n",
    "input_range = 4\n",
    "X = np.sort(rng.rand(N)*input_range - input_range/2)\n",
    "noise = rng.randn(N)*0.8\n",
    " \n",
    "linear = 5*X +noise\n",
    "quadratic =-2*X**2 +noise\n",
    "cubic = X**3 - 0.5*X**2 + noise\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c89e4176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializes a random number generator with a seed\n",
    "rng=np.random.RandomState(1680) \n",
    "# sets N and input_range \n",
    "N = 100\n",
    "input_range = 4\n",
    "# generates an array of size N, multiplying each value by 4 (scales array between 0 and 4), and then subtracting 2 from each value (array now scaled between -2 and 2)\n",
    "X = np.sort(rng.rand(N)*input_range - input_range/2)\n",
    "# generates an array called noise, multiplying each value by 0.8 \n",
    "noise = rng.randn(N)*0.8\n",
    "\n",
    "# generates an array of linearly distributed variables \n",
    "linear = 5*X +noise\n",
    "# generates an array of quadratic distributed variables \n",
    "quadratic =-2*X**2 +noise\n",
    "# generates an array of cubic distributed variables \n",
    "cubic = X**3 - 0.5*X**2 + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b36be45",
   "metadata": {},
   "source": [
    "#### 3. Produce a scatter plot that has all three series (linear, quadratic, and cubic) on the same set of axes with a legend identifying which color is which series and X on the x axis.\n",
    "Insert graph here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b91121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.scatter(X, linear, label='Linear', color='blue')\n",
    "plt.scatter(X, quadratic, label='Quadratic', color='green')\n",
    "plt.scatter(X, cubic, label='Cubic', color='red')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4a1b6",
   "metadata": {},
   "source": [
    "#### 4. Run three OLS regressions of the following specification:\n",
    "$$Y_i = b_1 * X$$\n",
    "Where $Y_i$ is first the linear output (i=1), then the quadratic output (i=2), and then the cubic output (i=3).\n",
    "$$ result_i = sm.OLS(Y_i,X).fit() $$\n",
    "Label each of these fitted regressions result1, result2, result3, respectivelty. Then summarize the resutls together in one table using summary_col:\n",
    "``` python\n",
    "print(summary_col([result1,result2,result3],stars=True,\n",
    "float_format='%0.2f', regressor_order=['x1'], info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs))}, model_names =['Linear\\n(Linear)', 'Linear\\n(Quadratic)',      'Linear\\n(Cubed)'],))\n",
    "```\n",
    "Insert that summary table here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4097f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================\n",
      "                Linear     Linear    Linear\n",
      "               (Linear) (Quadratic) (Cubed)\n",
      "-------------------------------------------\n",
      "x1             5.13***  0.29        2.42***\n",
      "               (0.07)   (0.30)      (0.15) \n",
      "R-squared      0.98     0.01        0.72   \n",
      "R-squared Adj. 0.98     -0.00       0.71   \n",
      "N              100      100         100    \n",
      "===========================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "result1 = sm.OLS(linear, X).fit()\n",
    "result2 = sm.OLS(quadratic, X).fit()\n",
    "result3 = sm.OLS(cubic, X).fit()\n",
    "print(summary_col([result1,result2,result3],stars=True,\n",
    "float_format='%0.2f', regressor_order=['x1'], info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs))}, model_names =['Linear\\n(Linear)', 'Linear\\n(Quadratic)','Linear\\n(Cubed)'],))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d46cd19",
   "metadata": {},
   "source": [
    "#### 5. Add a squared input to the regressors using: \n",
    "```\n",
    "data_sq = np.vstack((X,X**2)).T\n",
    "```\n",
    "and then run three OLS regressions of the following form\n",
    "$$ Y_i = \\beta_1 * X + \\beta_2 * X^2$$\n",
    "Where $Y_i$ is the first linear output (i=4), then the quadratic output (i=5), and then the cubic output (i=6). And label each of the regressions according to:\n",
    "``` python\n",
    "resulti = sm.OLS(Yi,data_sq).fit()\n",
    "```\n",
    "produce a summary table like in the previous question for regressions 1-6. Make the regressor order: \n",
    "``` python\n",
    "regressor_order = ['x1','x2']\n",
    "```\n",
    "Add the folling three element the model_names list for regressions 4-6:\n",
    "``` python\n",
    "'Quadratic\\n(Linear)','Quadratic\\n(Quadratic)','Quadratic\\n(Cubed)'\n",
    "```\n",
    "Insert that table here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2a6b5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "                Linear     Linear    Linear Quadratic  Quadratic  Quadratic\n",
      "               (Linear) (Quadratic) (Cubed)  (Linear) (Quadratic)  (Cubed) \n",
      "---------------------------------------------------------------------------\n",
      "x1             5.13***  0.29        2.42*** 5.13***   0.13*       2.37***  \n",
      "               (0.07)   (0.30)      (0.15)  (0.07)    (0.07)      (0.13)   \n",
      "x2                                          0.04      -1.96***    -0.53*** \n",
      "                                            (0.05)    (0.05)      (0.09)   \n",
      "R-squared      0.98     0.01        0.72    0.98      0.94        0.79     \n",
      "R-squared Adj. 0.98     -0.00       0.71    0.98      0.94        0.79     \n",
      "N              100      100         100     100       100         100      \n",
      "===========================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "data_sq = np.vstack((X, X**2)).T\n",
    "result4 = sm.OLS(linear, data_sq).fit()\n",
    "result5 = sm.OLS(quadratic, data_sq).fit()\n",
    "result6 = sm.OLS(cubic, data_sq).fit()\n",
    "print(summary_col([result1,result2,result3,result4,result5,result6],stars=True,\n",
    "float_format='%0.2f', regressor_order=['x1','x2'], info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs))}, model_names =['Linear\\n(Linear)', 'Linear\\n(Quadratic)','Linear\\n(Cubed)','Quadratic\\n(Linear)','Quadratic\\n(Quadratic)','Quadratic\\n(Cubed)'],))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ce98d2",
   "metadata": {},
   "source": [
    "#### 6. Add a cubed input (X**3) to the regressors from the previous question using vstack and then run three OLS regressions of the following form:\n",
    "\n",
    "$Y_i = β_1 * X +  β_2 * X^2+β_3 * X^3$\n",
    "\n",
    "produce a summary table like in the previous question for regressions 1-9. Make the regressor order:\n",
    "regressor_order=['x1','x2','x3']\n",
    "Add the following three elements the model_names list for regressions 7-9: \n",
    "'Cubed\\n(Linear)','Cubed\\n(Quadratic)','Cubed\\n(Cubed)'\n",
    "\n",
    "Insert that table here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96caed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================================================\n",
      "                Linear     Linear    Linear Quadratic  Quadratic  Quadratic  Cubed      Cubed     Cubed  \n",
      "               (Linear) (Quadratic) (Cubed)  (Linear) (Quadratic)  (Cubed)  (Linear) (Quadratic) (Cubed) \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "x1             5.13***  0.29        2.42*** 5.13***   0.13*       2.37***   5.18***  0.18        0.18    \n",
      "               (0.07)   (0.30)      (0.15)  (0.07)    (0.07)      (0.13)    (0.17)   (0.17)      (0.17)  \n",
      "x2                                          0.04      -1.96***    -0.53***  0.04     -1.96***    -0.46***\n",
      "                                            (0.05)    (0.05)      (0.09)    (0.05)   (0.05)      (0.05)  \n",
      "x3                                                                          -0.02    -0.02       0.98*** \n",
      "                                                                            (0.07)   (0.07)      (0.07)  \n",
      "R-squared      0.98     0.01        0.72    0.98      0.94        0.79      0.98     0.94        0.94    \n",
      "R-squared Adj. 0.98     -0.00       0.71    0.98      0.94        0.79      0.98     0.94        0.93    \n",
      "N              100      100         100     100       100         100       100      100         100     \n",
      "=========================================================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "data_cubed = np.vstack((X, X**2, X**3)).T\n",
    "result7 = sm.OLS(linear, data_cubed).fit()\n",
    "result8 = sm.OLS(quadratic, data_cubed).fit()\n",
    "result9 = sm.OLS(cubic, data_cubed).fit()\n",
    "print(summary_col([result1,result2,result3,result4,result5,result6,result7,result8,result9],stars=True,\n",
    "float_format='%0.2f', regressor_order=['x1', 'x2', 'x3'], info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs))}, model_names =['Linear\\n(Linear)', 'Linear\\n(Quadratic)','Linear\\n(Cubed)','Quadratic\\n(Linear)','Quadratic\\n(Quadratic)','Quadratic\\n(Cubed)','Cubed\\n(Linear)','Cubed\\n(Quadratic)','Cubed\\n(Cubed)'],))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bb838e",
   "metadata": {},
   "source": [
    "#### 7. Compare and contrast the coefficients over the 9 regressions in 3-4 sentences. You know that the linear, quadratic, and cubic output variables should have a linear, quadratic, and cubic relationship with the regressor X, respectively, based on the data generation. Do you notice anything surprising? What coefficients match your expectation based on the data generating process? \n",
    "\n",
    "\n",
    "Answer here: It makes sense that x1 has a statistically significant relationship with all the linear distributed data (columns 1, 4, 7) even as x2 and x3 gets added in the regression. It also makes sense that x2 has a statistically significant relationship with the quadratically distributed data (columns 5 and 8), and that x3 has a statistically significant relationship with the cubic distributed data (column 9). However, it is interesting that x1 has a statistically significant linear relationship with the cubic data (column 3 and 6) but it makes sense that this relationship goes away when x3 is added (column 9)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90196aa8",
   "metadata": {},
   "source": [
    "#### 8.  Now, re-run the data generation code from part 1 but make 1000 observations instead of 100. That is, N=1000. Run regressions i=1 through i=9, and produce a single summary table using summary_col with all 9 regressions results.\n",
    "\n",
    "Insert that table here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859a77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above\n",
    "N = 1000\n",
    "input_range = 4\n",
    "X = np.sort(rng.rand(N)*input_range - input_range/2)\n",
    "noise = rng.randn(N)*0.8\n",
    "linear = 5*X +noise\n",
    "quadratic =-2*X**2 +noise\n",
    "cubic = X**3 - 0.5*X**2 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6291a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sq = np.vstack((X, X**2)).T\n",
    "data_cubed = np.vstack((X, X**2, X**3)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae8b7a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=========================================================================================================\n",
      "                Linear     Linear    Linear Quadratic  Quadratic  Quadratic  Cubed      Cubed     Cubed  \n",
      "               (Linear) (Quadratic) (Cubed)  (Linear) (Quadratic)  (Cubed)  (Linear) (Quadratic) (Cubed) \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "x1             5.01***  -0.29***    2.37*** 5.02***   0.02        2.45***   5.01***  0.01        0.01    \n",
      "               (0.02)   (0.10)      (0.05)  (0.02)    (0.02)      (0.04)    (0.05)   (0.05)      (0.05)  \n",
      "x2                                          -0.01     -2.01***    -0.48***  -0.01    -2.01***    -0.51***\n",
      "                                            (0.01)    (0.01)      (0.03)    (0.01)   (0.01)      (0.01)  \n",
      "x3                                                                          0.00     0.00        1.00*** \n",
      "                                                                            (0.02)   (0.02)      (0.02)  \n",
      "R-squared      0.98     0.01        0.73    0.98      0.96        0.80      0.98     0.96        0.94    \n",
      "R-squared Adj. 0.98     0.01        0.73    0.98      0.96        0.80      0.98     0.96        0.94    \n",
      "N              1000     1000        1000    1000      1000        1000      1000     1000        1000    \n",
      "=========================================================================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "result1 = sm.OLS(linear, X).fit()\n",
    "result2 = sm.OLS(quadratic, X).fit()\n",
    "result3 = sm.OLS(cubic, X).fit()\n",
    "result4 = sm.OLS(linear, data_sq).fit()\n",
    "result5 = sm.OLS(quadratic, data_sq).fit()\n",
    "result6 = sm.OLS(cubic, data_sq).fit()\n",
    "result7 = sm.OLS(linear, data_cubed).fit()\n",
    "result8 = sm.OLS(quadratic, data_cubed).fit()\n",
    "result9 = sm.OLS(cubic, data_cubed).fit()\n",
    "print(summary_col([result1,result2,result3,result4,result5,result6,result7,result8,result9],stars=True,\n",
    "float_format='%0.2f', regressor_order=['x1', 'x2', 'x3'], info_dict={'N':lambda x: \"{0:d}\".format(int(x.nobs))}, model_names =['Linear\\n(Linear)', 'Linear\\n(Quadratic)','Linear\\n(Cubed)','Quadratic\\n(Linear)','Quadratic\\n(Quadratic)','Quadratic\\n(Cubed)','Cubed\\n(Linear)','Cubed\\n(Quadratic)','Cubed\\n(Cubed)'],))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aaa266",
   "metadata": {},
   "source": [
    "#### 9. What differences do you notice in the regression coefficients for N=100 versus N=1000? What similarities? Discuss these in 3-4 sentences. Hint: think about sample size.\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b8f668",
   "metadata": {},
   "source": [
    "# III.  CLUSTERING POLITICAL VARIABLES\n",
    "\n",
    "#### 10. Load the FLS-data.csv file from the HW2 page in canvas as ‘df_fls’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a042e606",
   "metadata": {},
   "source": [
    "#### 11. Create a dataframe called “df_clustering” that only contains the following variables about political status in the different countries:\n",
    "``` python\n",
    "['Bl Mkt Pm', \n",
    "    'Civl Lib',\n",
    "    'Yrs Open',\n",
    "    'Pol Rights',\n",
    "    'Rule of Law',\n",
    "    'War Dummy',\n",
    "    'Rev & Coup']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9278a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ea8ae",
   "metadata": {},
   "source": [
    "#### 12. Run the following code and explain each line.\n",
    "``` python\n",
    "df_scaled = normalize(df_clustering)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df_clustering.columns, index=df_clustering.index)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27ed43",
   "metadata": {},
   "source": [
    "12a. Insert the first 5 lines of df_scaled here. Hint: use .head()\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ff4e8",
   "metadata": {},
   "source": [
    "12b.  Why do you need to respecify column and index labels?\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f8fb9",
   "metadata": {},
   "source": [
    "#### 13. Plot a dendrogram using shc.dentrogram and shc.linkage for df_scaled with the ward method for the linkage (method=’ward’). \n",
    "13a. Add a title to the graph: \"Dendrogram of Countries Along Political Variables\" and\n",
    "present the graph below.\n",
    "\n",
    "Insert graph here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab963fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f40641",
   "metadata": {},
   "source": [
    "13b. Add plt.axhline(y= _, color=’r’, linestyle=’--‘) to plot to\n",
    "show where there is the largest gap between clusters. Hint: you need to set the\n",
    "“y=…” to a number. Produce a new graph with the line.\n",
    "\n",
    "Insert graph here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028d620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf3e914",
   "metadata": {},
   "source": [
    "13c. How many clusters does this imply you should have? Hint: look at where the\n",
    "dendrogram switches colors from top to bottom.\n",
    "\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3344f1b",
   "metadata": {},
   "source": [
    "#### 14. Create N clusters where N is the number of clusters from the previous question, using different clustering methods:\n",
    "14a.  Hierarchical Clustering: Use AgglomerativeClustering with the options for\n",
    "affinity=’euclidean’, and linkage=’ward’. Fit the prediction to df_scaled and save the cluster labels as a new column in the df_scaled dataframe with a column title\n",
    "‘HC labels’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862c4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da562211",
   "metadata": {},
   "source": [
    "14b. KMeans Clustering: Use KMeans with the option for random_state=1680. Fit\n",
    "KMeans to df_scaled and save the cluster labels as a new column in the df_scaled\n",
    "dataframe with a column title ‘KM labels’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059550e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25618165",
   "metadata": {},
   "source": [
    "#### 15. Create 4 clusters using different clustering methods: \n",
    "15a. Hierarchical Clustering: Use AgglomerativeClustering with the options for\n",
    "affinity=’euclidean’, and linkage=’ward’. Fit the prediction to df_scaled and save\n",
    "the cluster labels as a new column in the df_scaled dataframe with a column title\n",
    "‘HC labels 4’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6440d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc3015",
   "metadata": {},
   "source": [
    "15b. KMeans Clustering: Use KMeans with the option for random_state=1680. Fit\n",
    "KMeans to df_scaled and save the cluster labels as a new column in the df_scaled\n",
    "dataframe with a column title ‘KM labels 4’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee252f",
   "metadata": {},
   "source": [
    "#### 16. Run the following code to show how the HC labels from 14.a relate to the Civl Lib and Yrs Open variables in df_scaled.\n",
    "``` python\n",
    "plt.scatter(df_scaled['Civl Lib'], df_scaled['Yrs Open'], c=df_scaled['HC labels'])\n",
    "plt.xlabel('Civil Liberty Score (normalized)')\n",
    "plt.ylabel('Years as Open Economy (normalized)')\n",
    "plt.title('Civil Libertires vs. Open Economy:\n",
    "Countries in Hierarchical Clusters')\n",
    "plt.show()\n",
    "```\n",
    "Then adjust the code to produce graphs for [‘KM labels’, ‘HC labels 4’, ‘KM labels 4’].\n",
    "\n",
    "Insert the four graphs here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93d0910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cccb3c",
   "metadata": {},
   "source": [
    "#### 17. Calculate the first and second principal components of df_scaled using\n",
    "``` python \n",
    "PCA(n_components=2).fit_transform(df_scaled)\n",
    "```\n",
    "And add them to the df_scaled dataframe with titles ‘pc1’ and ‘pc2’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590ece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abdf5a7",
   "metadata": {},
   "source": [
    "17a. Produce four graphs showing the different clustering results [‘HC labels’,‘KC\n",
    "labels’, ‘HC labels 4’, ‘KM labels 4’] with the first principal component on the x\n",
    "axis and the second principal component on the y axis. Hint: use the code from 16\n",
    "as a template for plotting here, but be sure to change the axis labels and the title.\n",
    "\n",
    "Insert your four graphs here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cfa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c686b4",
   "metadata": {},
   "source": [
    "17b. Describe the differences in visualizing clusters using variables in 16 vs. using\n",
    "PCA in 17? Why does PCA help with visualization? Summarize your answers in\n",
    "2-3 sentences.\n",
    "\n",
    "Answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba512fce",
   "metadata": {},
   "source": [
    "# IV. OLS vs LASSO vs RIDGE REGRESSIONS\n",
    "#### 18. Run the following code to create training and testing splits of the df_fls dataframe\n",
    "*You will need to copy and paste the code below into a code block:*\n",
    "``` python\n",
    "y=df_fls['y']\n",
    "X=df_fls.drop(columns=['y'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1680)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a516512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f096406b",
   "metadata": {},
   "source": [
    "#### 19. Run an OLS regression on the training data. Produce the summary statistics using .summary() and paste them here:\n",
    "\n",
    "Summary: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb964d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4e805d",
   "metadata": {},
   "source": [
    "#### 20. Run a LASSO regression on the training data and search over different alpha parameters in using alphas=np.linspace(1e-6, 1, num=50). Hint: reference the review session example for coding LASSO.\n",
    "20a. What is the optimal alpha that you find?\n",
    "\n",
    "Answer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0439645",
   "metadata": {},
   "source": [
    "20b. Insert a plot of alphas on the x axis and cv_errors on the y axis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db1ef90",
   "metadata": {},
   "source": [
    "#### 21. Run a Ridge Regression on the training data and search over different alpha parameters in using alphas=np.linspace(1e-6, 1, num=50). Hint: reference the review session example for coding Ridge regressions.\n",
    "21a. What is the optimal alpha that you find? \n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb30753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4999f8a8",
   "metadata": {},
   "source": [
    "21b. Insert a plot of alphas on the x axis and cv_errros on the y axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb94f7",
   "metadata": {},
   "source": [
    "#### 22. Compare the regression coefficients from the three different approaches using:\n",
    "``` python\n",
    "coef_comp=pd.DataFrame({'var':X.columns, 'val_ols':olsReg.params.tolist(), 'val_lasso':lassoReg.coef_, 'var_ridge':ridgeReg.coef_})\n",
    "```\n",
    "\n",
    "22a. Insert the coef_comp table here:\n",
    "\n",
    "```\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d16f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94284fdf",
   "metadata": {},
   "source": [
    "22b. Write 2-3 sentences comparing the coefficients and explain why they are different.\n",
    "\n",
    "Answer here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39410cdd",
   "metadata": {},
   "source": [
    "22c. Look at the Table 4 in Varian (2014) (link to paper in Canvas). Compare you coefficients from LASSO to the column he has for the LASSO regression. Do you come to the same conclusions about which regressors to keep in the regression and their order of importance? If they are different, explain a possible reason for that.\n",
    "\n",
    "Answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231c3068",
   "metadata": {},
   "source": [
    "# V. CLASSIFICATION: LOGIT vs. NEURAL NETWORK\n",
    "\n",
    "#### 23. Load the titanic3.csv file in as \"df_titanic\" from HW2_data.zip in the Canvas Assignment for HW2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73975686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a8622d",
   "metadata": {},
   "source": [
    "#### 24. In Varian (2014), \"Big Data: New Tricks for Econometrics\", there is a discussion about wanting to allow for nonlinearity in age to affect the prediction of survival of Titanic passengers. This problem will compare estimating a logit with estimating neural network (multilayer perceptron). Explain the following lines of code and run them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d0624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.dropna(subset=['survived','age', 'sex','pclass'],inplace=True) \n",
    "df_titanic['female']= np.where(df_titanic['sex']=='female',1,0) \n",
    "y= df_titanic['survived']\n",
    "X= df_titanic[['age','pclass', 'female']] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1680) \n",
    "\n",
    "scaler=StandardScaler() \n",
    "scaler.fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "MLP = MLPClassifier(hidden_layer_sizes=(4,2),\n",
    "  random_state=1680,\n",
    "                    activation='logistic', solver='adam', \n",
    "                    max_iter =500,\n",
    "                    verbose=True, learning_rate_init=0.01) \n",
    "MLP.fit(X_train,y_train)\n",
    "print(accuracy_score(y_train,MLP.predict(X_train)))\n",
    "print(accuracy_score(y_test, MLP.predict(X_test)))\n",
    "\n",
    "logitmodel = LogisticRegression(solver='liblinear', random_state=1680).fit(X_train, y_train) \n",
    "print(accuracy_score(y_train,logitmodel.predict(X_train)))\n",
    "print(accuracy_score(y_test, logitmodel.predict(X_test)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641e347",
   "metadata": {},
   "source": [
    "24a. Compare the accuracy scores in-sample and out-of-sample for the logit regression and for the neural network in 2-3 sentences. \n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e25d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae2e97e",
   "metadata": {},
   "source": [
    "24b. Is the difference between the accuracies what you would have expected? Spend 2-3 sentences discussing possible explanations for the differences. \n",
    "\n",
    "Answer here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f61958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e7101d",
   "metadata": {},
   "source": [
    "24c. Print out the descriptive statistics for y_train and y_test\n",
    "\n",
    "Paste output here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ff243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86368c1e",
   "metadata": {},
   "source": [
    "#### 25. Now rerun the previous code, but add stratify=y into the train_test_split command.\n",
    "\n",
    "25a. How do the descriptive statistics for y_train and y_test change and how do the accuracy scores change?\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291119ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f274b",
   "metadata": {},
   "source": [
    "25b. What does “stratify” do and why would it change your results?\n",
    "\n",
    "Answer here:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab46b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d0460",
   "metadata": {},
   "source": [
    "#### 26. Look at the other variables in df_titanic. What other variables besides age do you think would be important in predicting survival?\n",
    "\n",
    "26a. List the variables you think of as important here and explain why you think they would improve prediction. Hint: you may need to transform variables into numerical representations/dummy variables.\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6346faf",
   "metadata": {},
   "source": [
    "26b. Run the logit regression with the variables that you listed and print the accuracy below. Did your accuracy improve?\n",
    "\n",
    "Answer here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9e80d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code you need (if any) to answer the questions above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff6ebcde2956354653a1bfc837161093b4abe74b5e977ba193ed76204ade37d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
